{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342e3863-20c9-452a-a39b-57fcc8d78aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 3s 0us/step\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 39s 20ms/step - loss: 0.1443 - accuracy: 0.9555 - val_loss: 0.0427 - val_accuracy: 0.9867\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.0455 - accuracy: 0.9862 - val_loss: 0.0403 - val_accuracy: 0.9861\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.0326 - accuracy: 0.9897 - val_loss: 0.0277 - val_accuracy: 0.9914\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 48s 25ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 0.0352 - val_accuracy: 0.9899\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.0304 - val_accuracy: 0.9913\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.0304 - accuracy: 0.9913\n",
      "\n",
      "✅ Test Accuracy: 0.9913\n",
      "1/1 [==============================] - 0s 148ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ✅ Import libraries\n",
    "import tensorflow as tf   #library used to build and train neural networks\n",
    "from tensorflow.keras import layers, models    #Used to create layers (like convolutional, dense) and build models\n",
    "import matplotlib.pyplot as plt     #Used for showing images/graphs\n",
    "import numpy as np             #Used for numerical operations like reshaping arrays\n",
    "\n",
    "# ✅ Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()         #Loads the MNIST dataset (70,000 handwritten digits),It automatically splits the data into training and testing sets\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "x_train = x_train / 255.0                    #Pixel values range from 0 to 255. Dividing by 255 normalizes them to 0–1\n",
    "x_test = x_test / 255.0                      #This helps the model train better and faster\n",
    "\n",
    "# Reshape images to (28, 28, 1) for CNN input,Each MNIST image is 28 pixels wide and 28 pixels tall — that's (28, 28).But to feed the image into a Convolutional Neural Network (CNN), we need to tell the model how many color channels the image has.\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)              #Adds a channel dimension (for grayscale images) so that each image is shaped as (28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)                 #Grayscale images (like MNIST digits) have 1 channel → shape: (28, 28, 1),Color images have 3 channels (Red, Green, Blue) → shape: (28, 28, 3)\n",
    "\n",
    "# ✅ Build the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)), #Finds patterns like lines, curves, etc., in the image\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),          #Reduces the size of the image (keeps important info)\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),       \n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),            \n",
    "\n",
    "    layers.Flatten(),                                      #Converts 2D image into a 1D vector for the Dense layers\n",
    "    layers.Dense(64, activation='relu'),                        #Fully connected layer with 64 neurons and ReLU activation\n",
    "    layers.Dense(10, activation='softmax')  # 10 output classes (digits 0-9), Final layer with 10 outputs for digits 0–9. Uses softmax to give probabilities\n",
    "])\n",
    "\n",
    "# ✅ Compile the model\n",
    "model.compile(optimizer='adam',           # Optimization algorithm (makes training efficient)\n",
    "              loss='sparse_categorical_crossentropy',                 #Suitable loss for classification of integer labels\n",
    "              metrics=['accuracy'])                             #Metric to track during training\n",
    "  \n",
    "# ✅ Train the model\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))          #Trains the model using the training data, Runs for 5 full passes over the dataset (epochs),Also checks accuracy on test data after each epoch\n",
    "\n",
    "# ✅ Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)              #Checks how good the model is on unseen test images\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# ✅ Predict the label of the first test image\n",
    "prediction = model.predict(x_test[0:1])                      #Predicts the class (digit) for the first image in the test set\n",
    "predicted_label = np.argmax(prediction)                      #np.argmax finds which digit has the highest predicted probability\n",
    "\n",
    "# ✅ Show prediction with the image\n",
    "plt.imshow(x_test[0].reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"Predicted Label: {predicted_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11890527-fc6f-4750-a6f4-7a4dcbecb895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
